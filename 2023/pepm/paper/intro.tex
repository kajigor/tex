\section{Introduction}


There is a well-known observation\cite{relational_solvers_for_seach_problems,semantics_modifiers} that programs solving certain problems can
be acquired by inverting programs solving some other, much simpler, problems. Sometimes
the difference in the ``simplicity'' can be characterized in precise complexity-theoretic terms:
for example, type checking for simple typed lambda calculus (STLC) is known to be
linear-time~\cite{find_one} (and rather straightforward to implement), while type inference (its inversion)
is PTIME-complete~\cite{find_one}, and type inhabitation problem (its another inversion) is
PSPACE-complete~\cite{find_one}. In the scope of this paper we will be interested in a more
concrete scenario of this generic idea application, namely, the scenario of turning \emph{verifiers}
into \emph{solvers}. Indeed, for the variety of search problems the implementation of
a verifier (a procedure which, given an instance of the problem and some \emph{sample}, verifies if
this sample is a solution) is straighforward; on the other hand its inversion (which takes an
instance of the problem and returns such a sample which makes the verifier to succeed) is a
solver, which as a rule is much harder to implement in an explicit manner. Of course,
the properties of the solver produced in such a way greatly depend on the program inversion approach
utilized, which exist a few~\cite{URA,some_gluck_papers_on_invertible_computations}; we, specifically,
focus on the application of \emph{relational programming}~\cite{The_reasoned_schemer}
as a way to run programs in the reverse direction.

Relatonal programming can be considered as a subfield of conventional logic programming focused on
study of implementation techniques and applications of \emph{purely relational} specifications. In a
narrow sense relational programming amounts to writing programs in \mk\footnote{\url{minikanren.org}}~--- an embedded DSL initially
developed for \textsc{Scheme} and later ported for dozens of other host languages. Based on the same
theory of first-order Horn clauses as, for example, \prolog, \mk employs a complete \emph{interleaving search}\cite{monad_transformers, our_paper_on_cemantics_APLAS} and
discourages the use of extra-logical features such as knowledge of concrete search order, ``cuts'', side-effects, efficient, but non-relational arithmetic, etc. Thus,
contrary to conventional logic programming, where the specification provided by an end-user as a rule encodes a
certain concrete way to solve a problem, in \mk the focus shifted even more into the specification of the
problem itself with no certain hints of how to solve its various instances. On one hand this makes the specifications
written in \mk short, elegant and expressible. It is possible with \mk to directly employ the verifier-to-solver
approach~\cite{type-inferencer,pattern-matching-APLAS}, and sometimes with practically applicable results~\cite{UI_generation_minikanren_2022,LOPSTR_2023}. On the other
hand, many useful optimization techniques can not be applied for \mk programs directly since these programs
lack an important part of information~--- the \emph{direction} under which relational verifier turns into a solver.

In this paper we present the results of our exploration in the area of \emph{mode inference} and \emph{functional conversion} for \mk.
Mode analysis and inference is a relevant technique for conventional logic programming~\cite{mercury et al}: given a user-defined
description of \emph{modes} for (some) relations (which can be considered as an implicit specification of a direction in which
these relations are intended to be evaluated) mode analysis propagates the mode information through the rest of logic program thus
defining more concrete evaluation strategy for the rest of its relations. Various notions and concrete approaches are employed
for mode analysis in various settings, and we give a survey in Section~\ref{sec:related_work}. In our setting we consider user-defined
mode specification for the top-level goal as the prescription of the direction in which relational specification has to
be evaluated to provide a solver for the problem in question. However, such a prescription can not be directly employed in \mk as it
contradicts the very nature of relational programming. Instead, we accompany mode inference with \emph{functional conversion}~---
a transformation which, given a relational specification, top-level goal, user-defined modes for this goal and the results of mode
inference provides a regular functional program which delivers exactly the same answers as that top-level goal being evaluated
in the direction prescribed by that user-defined modes. In addition functional conversion can sometimes eliminate the
interpretation overhead introduced by \mk implementation as a shallow DSL: it is capable of replacing unification with
patern-matching, make use of deterministic order of evaluation (if such an order is discovered by mode inference), etc.
The contribution of this paper is as follows:

\begin{itemize}
\item We reiterate on mode inference for \mk, specifying concrete requirements
  specific for both \mk and our ultimate goal of putting verifier-to-solver
  idea to work.
\item We describe a concrete approach to mode inference which takes all aforementioned
  requirements into account. As generally mode inference is known to be undecidable we
  develop a number of heuristics specific to our case.
\item We implement both mode inference and functional conversion for a reference
  \mk implementation.
\item We evaluate our implementation on a number of benchmarks, partially
  taken from existing literature, to investigate the advantages, drawback, and
  potential ways for improvement of our approach.
\end{itemize}

The rest of the paper is structures as follows. ...




\begin{comment}
\emph{Inverse computation} is the technique in which a program can be automatically inverted to solve problems different from its original purpose.
For example, by inverting a sorting function, one can generate permutations; by inverting multiplication, one achieves division.
In the context of software development, inverse computations open the door to verifier-to-solver approach.
In it, a verifier, whose primary purpose is to check whether a candidate solution is indeed a solution to a problem, is inverted to become a solver.
This way, an interpreter for a programming language can be used for program synthesis, a type checker---to solve type inhabitation problem and so on~\cite{Untagged, lozov2019relational}.

There are multiple approaches to inverse computations such as universal resolving algorithm~\cite{RevURA} and semantics modifiers~\cite{SemanticsModifiers1}.
The one, which we are considering in this paper, employs \emph{relational programming}.
It is a powerful paradigm which, akin to logic programming, is based on Horn clauses.
Contrary to such languages as \prolog, the relational paradigm discourages the use of extra-logic features such as cut and instead employs interleaving search strategy to guarantee the completeness of search.
Thanks to the latter, it is also not expected that a program is deterministic, i.e. produces at most one result, which plays an important role in enabling verifier-to-solver approach.

In a narrow sense, relational programming means programming in a \mk language\todo{footnote}.
It is a family of small yet powerful embedded DSLs whose aim is to bring the benefits of logic programming into a general-purpose programming language.
A relational program exist as a part of a host program, which utilizes query results in some way.
The host languages are not expected to be able to process logic variables, nondeterminism and other aspects of relational computations.
The host program usually only deals with a finite subset of answers, which have been reified into a ground representation, meaning the answer do not contain any logic variables.

When a relation is expected to produce ground answers, and the direction in which it is intended to be run is known, then it becomes possible to convert it into a function which may execute significantly faster than its relational counterpart.
Performance improvement comes from reducing inherent interpretation overhead as well as replacing expensive unifications with considerably faster equality checks, assignments and pattern matches of the host language.
An informal functional conversion scheme was introduced in the paper~\cite{verbitskaia2022direction}and a semi-automatic functional conversion algorithm and implementation for a minimal core relational programming language \micro was described in~\footnote{cite mk 2023}.

\todo{What's the contribution?}

This paper focuses on converting to the target languages of \haskell and \ocaml, although other languages can also be considered as potential target languages.
Our evaluation showed performance improvement of $2.5$ times for propositional formulas synthesis and up to $3$ orders of magnitude improvement for relations over Peano numbers.
\end{comment}
