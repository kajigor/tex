\section{Functional Conversion in \mk}

In this section, we describe the functional conversion algorithm.
The reader is encouraged to first read the paper \todo{(cite)} on the topic, which introduces the conversion scheme on a series of examples.

Functional conversion is done for a relation with a concrete fixed direction.
The goal is to create a function which computes the same answers as \mk would, not necessarily in the same order.
Since the search in \mk is complete, both conjuncts and disjuncts can be reordered freely: interleaving makes sure that no answers would be lost this way.
Moreover, the original order of the subgoals is often suboptimal for any direction but the one which the programmer had in mind when they encoded the relation.
When relational conversion is used to create a relation, the order of the subgoals only really suits the forward direction, whereas the relation is not intended to be run in it.

The mode inference results in the relational program with all variables annotated by their modes, and all base subgoals ordered in a way that further conversion makes sense.
Conversion then produces functions in the intermediate language.
It may be further pretty printed into concrete functional programming languages, in our case \haskell and \ocaml.


\subsection{Mode Inference}

We employ a simple version of mode analysis to order subgoals properly in the given direction.
The mode analysis makes sure that a variable is never used before it is associated with some value.
It also ensures that once a variable becomes ground, it never becomes free, thus the value of a variable is never lost.
The mode inference pseudocode is presented in figure~\ref{fig:modeInference}.

\input{fig/mode_inference}

Mode inference starts by initializing modes for all variables in the body of the given relation according to the given direction.
All variables which are among arguments are annotated with their \inm or \outm modes, while all other variables get only their initial instantiations specified as $f$.

Then the body of the relation is analyzed (see line \todo{(reference)} in figure \todo{(reference)}).
Since the body is normalized, it can only be a disjunction.
Each disjunct is analyzed independently, because no data flow happens between them.

Analyzing conjunctions involves analyzing subgoals and ordering them.
Let us first consider mode analysis of unifications and calls and then circle back to the way we order them.
Whenever a base goal is analyzed, all variables in it has some initial instantiation, and some of them also have some final instantiation.
Mode analyzing a base goal boils down to making all final instantiations ground.

When analyzing a unification, several situations may occur.
Firstly, every variable in the unification can be ground, as in $x^{g \rightarrow g} \equiv O$ or in $y^{g \rightarrow ?} \equiv z^{g \rightarrow ?}$ (here $?$ is used to denote that a final instantiation is not yet known).
We call this case \emph{guard}, since it is equivalent to checking that two values are the same.

The second case is when one side of a unification only contains ground variables.
Depending on which side is ground, we call this either \emph{assignment} or \emph{match}.
The former corresponds to assigning the value to a variable, as in $x^{f \rightarrow ?} \equiv S \, x_1^{g \rightarrow g}$ or $x^{g \rightarrow g} \equiv y^{f \rightarrow ?}$.
The latter --- to pattern matching with the variable as the scrutinee, as in $x^{g \rightarrow g} \equiv S \, x_1^{f \rightarrow ?}$.
Notice that we allow some variables in the right-hand side to be ground in matches, given that at least one of them is free.

The last case occurs when both the left-hand and right-hand sides contain free variables.
This does not translate well into functional code.
Any free logic variable corresponds to the possibly infinite number of ground values.
To handle this kind of unifications, we propose to use \emph{generators} which produce all possible values a free variable may have.

We base our ordering strategy for conjuncts on the fact that these four different unification types have different costs.
The guards are just equality checks, which are inexpensive and can reduce the search space considerably.
Assignments and matches are more involved, but they still take much less effort, than generators.
Moreover, executing non-generator conjuncts first may make some of the variables of the prospective generator ground, thus avoiding generation in the end.

This is the base reasoning which is behind our ordering strategy.
The function \lstinline{pickConjunction} selects first guard unification it can find.
If no guard is present, then it searches for the first assignment, then for the match.
If all unifications in the conjunction are generators, then the search continues among relation calls.
First it selects relation calls with all ground arguments, then with some ground arguments, and only if there are non of those, it picks a generator.

Once one conjunct is picked, it is analyzed.
The picked conjunct may instantiate new variables, thus this information is propagated onto the rest of the conjuncts.
Then the rest of the conjuncts is mode analyzed as a new conjunction.
If any new modes for any of the relations are encountered, they are also mode analyzed.

It is worth noticing that any relation can be a generator.
We cannot judge the relation to be a generator solely by its mode: the addition relation in the mode \lstinline{add$^o$ x$^{g \rightarrow g}$ y$^{f \rightarrow g}$ z$^{f \rightarrow g}$} generates an infinite stream, while \lstinline{add$^o$ x$^{f \rightarrow g}$ y$^{f \rightarrow g}$ z$^{g \rightarrow g}$} does not \todo{(check)}.

\subsection{Conversion into Intermediate Representation}

\subsection{Conversion into Concrete Languages}